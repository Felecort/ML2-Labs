{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ссылка на скачивание датасета\n",
    "link = \"https://archive.ics.uci.edu/static/public/17/breast+cancer+wisconsin+diagnostic.zip\"\n",
    "# сформируем имена колонок\n",
    "# имена признаков, которые повторяются три раза\n",
    "features = [\n",
    "    \"radius\",\n",
    "    \"texture\",\n",
    "    \"perimeter\",\n",
    "    \"area\",\n",
    "    \"smoothness\",\n",
    "    \"compactness\",\n",
    "    \"concavity\",\n",
    "    \"concave_points\",\n",
    "    \"symmetry\",\n",
    "    \"fractal_dimension\"\n",
    "]\n",
    "# повторяем имена признаков три раза с разными индексами \n",
    "# и добавляем имена первых двух колонок с помощью \n",
    "# контатенации списков оператором `+`\n",
    "# [\"id\", \"class\"] + [\"radius-1\", \"area-1\", ...] + [\"radius-2\", \"area-2\", ...\n",
    "names = sum(([f\"{f}-{i}\" for f in features] for i in range(1, 4)), ['id', 'class'])\n",
    "raw_data = pd.read_csv(link, names=names)\n",
    "# посмотрим на результат\n",
    "raw_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Слегка преобработаем данные\n",
    "# 1. Уберем колонку id\n",
    "data = raw_data.drop([\"id\"], axis=1)\n",
    "# 2. Закодируем метку числом 0 и 1 \n",
    "data[\"class\"], class_labels = pd.factorize(data[\"class\"])\n",
    "print(\"Class labels:\", class_labels)\n",
    "# посмотрим на результат\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x = train_test_split(data, test_size=0.2, random_state=2023)\n",
    "train_y, test_y = train_x.pop(\"class\"), test_x.pop(\"class\")\n",
    "# посмотрим на результат\n",
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# создаем модель keras\n",
    "base_model = tf.keras.Sequential(\n",
    "    layers=[ # описываем слои нейронной сети\n",
    "        layers.Dense( # создаем полносвязный слой\n",
    "            16, # количество нейронов \n",
    "            activation='relu', # функция активации\n",
    "            input_dim=train_x.shape[1]\n",
    "        ), # количество нейронов на входе, \n",
    "        # нужно тольно для первого слоя\n",
    "        layers.Dense(8, activation='relu'), # так же задаем второй слой\n",
    "        layers.Dense(6, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid') # выходной слой\n",
    "    ],\n",
    "    name=\"breast-cancer-base-model\",\n",
    ")\n",
    "# посмотрим описание модели\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_history = base_model.fit(\n",
    "    train_x, train_y,\n",
    "    epochs=40,\n",
    "    batch_size=20,\n",
    "    validation_data=(test_x, test_y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Dict, List, Tuple\n",
    "def plot_history(\n",
    "                history: Dict[str, List[float]],\n",
    "                title: str = \"\",\n",
    "                metric_name: str = 'loss',\n",
    "                ylim: Tuple[float, float] = None\n",
    "    ):\n",
    "\n",
    "    train_values = history[metric_name]\n",
    "    plt.plot(train_values, label=f'Train {metric_name}')\n",
    "    try:\n",
    "        val_values = history['val_' + metric_name]\n",
    "        plt.plot(val_values, label=f'Validation {metric_name}')\n",
    "    except KeyError:\n",
    "        val_values = []\n",
    "    plt.title(title)\n",
    "    all_values = train_values + val_values\n",
    "    ylim = ylim or (0.9 * min(all_values), 1.1 * max(all_values))\n",
    "    plt.ylim(ylim)\n",
    "    plt.ylabel(metric_name.capitalize())\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_history(base_model_history.history, \"Основная модель\", \"accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses, datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x, train_y), (test_x, test_y) = datasets.mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    " plt.subplot(5,5,i+1)\n",
    " plt.xticks([])\n",
    " plt.yticks([])\n",
    " plt.grid(False)\n",
    " plt.imshow(train_x[i])\n",
    " plt.xlabel(str(train_y[i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_model = tf.keras.Sequential(\n",
    "    [\n",
    "        layers.Flatten(input_shape=(28, 28, 1)),\n",
    "        layers.Rescaling(1 / 255),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(10),\n",
    "        layers.Softmax()\n",
    "    ],\n",
    "    name=\"mnist-base-model\",\n",
    ")\n",
    "# посмотрим описание модели\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%time\n",
    "base_model_history = base_model.fit(\n",
    "    train_x, train_y,\n",
    "    epochs=40,\n",
    "    batch_size=100,\n",
    "    validation_data=(test_x, test_y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_history(base_model_history.history, \"Основная модель\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_model_history.history['val_accuracy'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/aut\n",
    "url = https://archive.ics.uci.edu/static/public/9/auto+mpg.zip\n",
    "column_names = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight',\n",
    " 'Acceleration', 'Model Year', 'Origin']\n",
    "raw_dataset = pd.read_csv(url, names=column_names,\n",
    " na_values='?', comment='\\t',\n",
    " sep=' ', skipinitialspace=True)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
